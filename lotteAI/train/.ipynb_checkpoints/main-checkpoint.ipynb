{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f7c1567-9f99-4d80-9f14-86ccb2f463dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2> 0. 데이터 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "357b746f-896c-4abd-a50a-424b507c06e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open /Users/sungheui/코딩, /Users/sungheui/코딩.zip or /Users/sungheui/코딩.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!unzip /Users/sungheui/코딩 테스트/ArtClassify/train.zip -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbcba67f-0f8b-49fa-9908-1f9ed8293e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sungheui/sh/lotteAI'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0598875a-f8e9-4265-86fb-8686d30e6b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps 사용 가능 여부: True\n",
      "mps 지원 환경 여부: True\n"
     ]
    }
   ],
   "source": [
    "#환경 설정 확인하기\n",
    "import torch\n",
    "print(f\"mps 사용 가능 여부: {torch.backends.mps.is_available()}\")\n",
    "print(f\"mps 지원 환경 여부: {torch.backends.mps.is_built()}\")\n",
    "\n",
    "#GPU check DEVICE\n",
    "# print(f'PyTorch Version : [{torch.__version__}]')\n",
    "# device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f'Device : [{device}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b274d6-e42d-4844-ae4a-01441c0f6961",
   "metadata": {},
   "source": [
    "<h3> 2. 라이브러리 import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11deab99-8c0b-4277-b768-d3d3000f6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from glob import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902df84-0de7-4854-9e65-a52982dc3261",
   "metadata": {},
   "source": [
    "<h3> 3. Config setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9360ae75-537b-464e-9733-9ae49ef4ca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version : [2.1.2]\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "#CONFIG\n",
    "torch.manual_seed(128)\n",
    "BATCH_SIZE= 2\n",
    "EPOCHS=40\n",
    "LEARNING_RATE=1e-3\n",
    "print(f'PyTorch Version : [{torch.__version__}]')\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90febacd-53ed-49f4-ad0e-dd27018d1074",
   "metadata": {},
   "source": [
    "<h3> 4. Custom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "283ae72c-6bf4-4015-b058-76175221b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb;pdb.set_trace() \n",
    "class LotteDataset(Dataset):\n",
    "  def __init__(self, data_root, train_mode, transform=None):\n",
    "    super(LotteDataset, self).__init__()\n",
    "    self.train_mode=train_mode\n",
    "    self.transform = transform\n",
    "    self.label2idx = {'dog': 0,\n",
    "             'elephant': 1,\n",
    "             'giraffe': 2,\n",
    "             'guitar': 3,\n",
    "             'horse': 4,\n",
    "             'house': 5,\n",
    "             'person': 6}\n",
    "   \n",
    "    if self.train_mode==False:\n",
    "        \n",
    "        self.img_list= []\n",
    "        img_list = []\n",
    "        for file in os.listdir(data_root):\n",
    "            file_root = os.path.join(data_root, file)\n",
    "            for data in os.listdir(file_root):\n",
    "                data_path = os.path.join(file_root, data)\n",
    "                img_list.append(data_path)\n",
    "        self.img_list = sorted(img_list)\n",
    "        \n",
    "    else: #학습할 때 \n",
    "        self.img_list = []\n",
    "        self.label_list=[]\n",
    "        img_list = []\n",
    "        for file in os.listdir(data_root):\n",
    "            file_root = os.path.join(data_root, file)\n",
    "            for data in os.listdir(file_root):\n",
    "                data_path = os.path.join(file_root, data)\n",
    "                img_list.append(data_path)\n",
    "        self.img_list = sorted(img_list)\n",
    "\n",
    "        for label in img_list:\n",
    "            label = label.split('/')[3]\n",
    "            self.label_list.append(self.label2idx[label]) \n",
    "            \n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.img_list)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    img_path = self.img_list[index]\n",
    "    \n",
    "    if self.train_mode:\n",
    "        label = self.label_list[index]\n",
    "     \n",
    "\n",
    "    # Image Loading\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    if self.transform:\n",
    "      img = self.transform(img)\n",
    "\n",
    "    if self.train_mode:\n",
    "      return img,label\n",
    "    else:\n",
    "      return img\n",
    "\n",
    "# if __name__=='__main__':\n",
    "#     data = LotteDataset('./dataset/train',train_mode=True,transform=train_transforms)\n",
    "#     q= data.__getitem__(1)\n",
    "#     print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80e6a86f-f05d-411c-9fe2-50b457062d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapTransform(Dataset):\n",
    "    def __init__(self, dataset, transform, train_mode):\n",
    "        self.dataset = dataset\n",
    "        self.transform=transform\n",
    "        self.train_mode=train_mode\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train_mode:\n",
    "          return self.transform(self.dataset[index][0]), self.dataset[index][1]\n",
    "        else:\n",
    "          return self.transform(self.dataset[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f2a3160-bc43-464a-a228-558009425e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trian Augmentation \n",
    "train_transforms=transforms.Compose([\n",
    "    transforms.RandomChoice([\n",
    "        transforms.ColorJitter(brightness=(1,1.1)),\n",
    "        transforms.ColorJitter(contrast=0.1), \n",
    "        transforms.ColorJitter(saturation=0.1),\n",
    "    ]),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.RandomAffine(degrees=15, translate=(0.2, 0.2), scale=(0.8, 1.2), shear=10,fill=255),\n",
    "        transforms.RandomCrop((224,224)),\n",
    "    ]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "#Test Augmentation \n",
    "test_transforms=transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Resize((224,224)),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                          [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0855238-d1d0-42dc-9735-a0dc28c60739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#그냥 \n",
    "train_data=LotteDataset('./dataset/train',train_mode=True)\n",
    "test_data=LotteDataset('./dataset/test',train_mode=False)\n",
    "\n",
    "trans_train_data=MapTransform(train_data,train_transforms,train_mode=True)\n",
    "trans_test_data=MapTransform(test_data,test_transforms,train_mode=False)\n",
    "\n",
    "train_iter=DataLoader(trans_train_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
    "test_iter=DataLoader(trans_test_data,batch_size=BATCH_SIZE,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11fa3dc9-fef5-4ca8-bd23-ff0a6a8226a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##cross-validation 할때 이걸로 \n",
    "# all_data=LotteDataset('./dataset/train',train_mode=True,transform=train_transforms)\n",
    "# test_data=LotteDataset('./dataset/test',train_mode=False,transform=test_transforms)\n",
    "# test_iter=DataLoader(test_data,batch_size=BATCH_SIZE,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "804f8af7-23d4-451a-89df-be9da3d30fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1698\n",
      "351\n"
     ]
    }
   ],
   "source": [
    "print(len(all_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b24b378-8efa-4b8f-93a6-1ff2accd2cdc",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<h3> 5. Model Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af7a123f-6f8b-4280-9766-5a21244192ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import import_ipynb\n",
    "#현재 디렉토리 찾기 \n",
    "# os.getcwd()\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train.tt import VIT2\n",
    "\n",
    "model = VIT2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ada36fd-bcf4-463c-ae72-e183d177db00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_embeddings\n",
      "model.head.weight\n",
      "model.head.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad==True:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3541e5fb-b2fe-49d5-87c3-3a7c00427110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss label smooth\n",
    "def loss_fn(outputs, targets):\n",
    "    if len(targets.shape) == 1:\n",
    "        return F.cross_entropy(outputs, targets)\n",
    "    else:\n",
    "        return torch.mean(torch.sum(-targets * F.log_softmax(outputs, dim=1), dim=1))\n",
    "\n",
    "def label_smooth_loss_fn(outputs, targets, epsilon=0.1):\n",
    "    onehot = F.one_hot(targets, 1000).float().to(device)\n",
    "    targets = (1 - epsilon) * onehot + torch.ones(onehot.shape).to(device) * epsilon / 1000\n",
    "    return loss_fn(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ceb522f-e58f-48d9-a0b1-b5663cc8422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(Model,data_iter,loss):\n",
    "    with torch.no_grad():\n",
    "      Model.eval()\n",
    "      n_total, n_correct = 0,0\n",
    "      loss_val_sum=0\n",
    "      print(\"(Train or Validation) Data Testing....\\n\")\n",
    "      for imgs, labels in iter(data_iter):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        model_pred=Model(imgs)\n",
    "\n",
    "        loss_out=loss(model_pred,labels)\n",
    "        loss_val_sum+=loss_out\n",
    "\n",
    "        _, y_pred=torch.max(model_pred.data,1)\n",
    "        n_correct+=(y_pred==labels).sum().item()\n",
    "        n_total+=imgs.size(0)\n",
    "      val_accr=(n_correct/n_total)\n",
    "      Model.train()\n",
    "      loss_val_avg=loss_val_sum/len(data_iter)\n",
    "    print(\"Testing Done.\\n\")\n",
    "    return val_accr,loss_val_avg\n",
    "    \n",
    "def get_submission(Model,data_iter,epoch,fold):\n",
    "  with torch.no_grad():\n",
    "    Model.eval()\n",
    "    pred_label=[]\n",
    "    print(\"Final Testing....\\n\")\n",
    "    for imgs in iter(test_iter):\n",
    "      model_pred=Model(imgs.to(device))\n",
    "\n",
    "      _, y_pred=torch.max(model_pred.data,1)\n",
    "      pred_label.extend(y_pred.tolist())\n",
    "\n",
    "  Model.train()\n",
    "\n",
    "  submission = pd.read_csv('./dataset/test_answer_sample_.csv', encoding = 'utf-8')\n",
    "  submission['prediction'] = pred_label\n",
    "  submission.to_csv('./submission_50Resnext'+str(fold)+'_'+str(epoch)+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557fd2fb-9480-4678-9610-6c87abbfb627",
   "metadata": {},
   "source": [
    "<h3> Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c06fd-7acb-474e-8637-cdf05d8703ee",
   "metadata": {},
   "source": [
    "<h2> cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4f4ba53-bfad-420b-9656-b54d3b5a0cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "folds=StratifiedKFold(n_splits=4,shuffle=True)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "##Loss Function 택1\n",
    "# loss=label_smooth_loss_fn\n",
    "loss = loss_fn \n",
    "f = open(\"./vitPrompt_trainlog2.txt\", 'w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8b922b0-dbff-4dca-82ba-82bb19a4013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "::::::::: Fold : 0 :::::::::::\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[0] train loss:[2.12894] vali loss:[2.04196] vali_accr:[0.31294]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[1] train loss:[1.97640] vali loss:[1.90548] vali_accr:[0.39059]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[2] train loss:[1.86195] vali loss:[1.79986] vali_accr:[0.49176]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[3] train loss:[1.75624] vali loss:[1.70568] vali_accr:[0.53412]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[4] train loss:[1.66740] vali loss:[1.61485] vali_accr:[0.56471]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[5] train loss:[1.56542] vali loss:[1.54495] vali_accr:[0.57176]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[6] train loss:[1.49631] vali loss:[1.45767] vali_accr:[0.60471]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[7] train loss:[1.42876] vali loss:[1.41004] vali_accr:[0.62353]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[8] train loss:[1.36144] vali loss:[1.35054] vali_accr:[0.61882]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[9] train loss:[1.30558] vali loss:[1.28284] vali_accr:[0.65412]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[10] train loss:[1.26437] vali loss:[1.23253] vali_accr:[0.66824]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[11] train loss:[1.21269] vali loss:[1.20653] vali_accr:[0.64000]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[12] train loss:[1.16577] vali loss:[1.16810] vali_accr:[0.65176]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[13] train loss:[1.12187] vali loss:[1.13709] vali_accr:[0.66588]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[14] train loss:[1.09464] vali loss:[1.09646] vali_accr:[0.66118]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[15] train loss:[1.04389] vali loss:[1.02857] vali_accr:[0.69176]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[16] train loss:[1.03624] vali loss:[1.05742] vali_accr:[0.67765]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[17] train loss:[0.99339] vali loss:[1.02274] vali_accr:[0.67529]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[18] train loss:[0.95428] vali loss:[0.99151] vali_accr:[0.70118]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[19] train loss:[0.95077] vali loss:[0.96800] vali_accr:[0.69647]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[20] train loss:[0.92167] vali loss:[0.94012] vali_accr:[0.69412]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[21] train loss:[0.88863] vali loss:[0.94008] vali_accr:[0.69882]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[22] train loss:[0.88405] vali loss:[0.90114] vali_accr:[0.71059]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[23] train loss:[0.84849] vali loss:[0.89467] vali_accr:[0.71765]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[24] train loss:[0.84261] vali loss:[0.88759] vali_accr:[0.71294]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[25] train loss:[0.84337] vali loss:[0.88065] vali_accr:[0.72000]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[26] train loss:[0.80204] vali loss:[0.85202] vali_accr:[0.71529]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[27] train loss:[0.79033] vali loss:[0.81102] vali_accr:[0.73176]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[28] train loss:[0.77713] vali loss:[0.82585] vali_accr:[0.73412]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[29] train loss:[0.76865] vali loss:[0.84646] vali_accr:[0.71294]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[30] train loss:[0.75596] vali loss:[0.82162] vali_accr:[0.72000]\n",
      "\n",
      "Model Save....\n",
      "\n",
      "Epoch 00031: reducing learning rate of group 0 to 5.0000e-07.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[31] train loss:[0.74034] vali loss:[0.79596] vali_accr:[0.74118]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[32] train loss:[0.73943] vali loss:[0.78675] vali_accr:[0.73176]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n",
      "Testing Done.\n",
      "\n",
      "Final Testing....\n",
      "\n",
      "epoch:[33] train loss:[0.72714] vali loss:[0.78615] vali_accr:[0.74353]\n",
      "\n",
      "Model Save....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train or Validation) Data Testing....\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     loss_val_sum\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss_out\n\u001b[1;32m     30\u001b[0m loss_val_avg\u001b[38;5;241m=\u001b[39mloss_val_sum\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_iter)\n\u001b[0;32m---> 31\u001b[0m vali_accr,vali_loss\u001b[38;5;241m=\u001b[39m\u001b[43mfunc_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvali_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     33\u001b[0m   get_submission(model,test_iter,epoch,current_fold)\n",
      "Cell \u001b[0;32mIn[43], line 16\u001b[0m, in \u001b[0;36mfunc_eval\u001b[0;34m(Model, data_iter, loss)\u001b[0m\n\u001b[1;32m     13\u001b[0m   loss_val_sum\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss_out\n\u001b[1;32m     15\u001b[0m   _, y_pred\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmax(model_pred\u001b[38;5;241m.\u001b[39mdata,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m   n_correct\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m   n_total\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mimgs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m val_accr\u001b[38;5;241m=\u001b[39m(n_correct\u001b[38;5;241m/\u001b[39mn_total)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(BATCH_SIZE)\n",
    "for current_fold,(train_idx, vali_idx) in enumerate(folds.split(all_data,all_data.label_list)):\n",
    "    \n",
    "  train_data=torch.utils.data.Subset(all_data,train_idx)\n",
    "  vali_data=torch.utils.data.Subset(all_data,vali_idx)\n",
    "    \n",
    "  train_iter=DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
    "  vali_iter=DataLoader(vali_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
    "\n",
    "  print(f'::::::::: Fold : {current_fold} :::::::::::\\n')\n",
    "  f.write(f'::::::::: Fold : {current_fold} :::::::::::\\n')\n",
    "  # model.train()\n",
    "  prev_vali_loss=100\n",
    "  best_vali_loss=100\n",
    "  flag=0\n",
    "  over_check=0\n",
    "  for epoch in range(EPOCHS) :\n",
    "    # if epoch==3:\n",
    "    #   freeze(Model,-3)\n",
    "    loss_val_sum=0\n",
    "    for imgs, labels in iter(train_iter):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        model_pred=model(imgs)\n",
    "        loss_out = loss(model_pred, labels)\n",
    "        scaler.scale(loss_out).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        loss_val_sum+=loss_out\n",
    "    loss_val_avg=loss_val_sum/len(train_iter)\n",
    "    vali_accr,vali_loss=func_eval(model,vali_iter,loss_fn)\n",
    "    if epoch>=0:\n",
    "      get_submission(model,test_iter,epoch,current_fold)\n",
    "      print(\"epoch:[%d] train loss:[%.5f] vali loss:[%.5f] vali_accr:[%.5f]\\n\"%(epoch,loss_val_avg,vali_loss,vali_accr))\n",
    "      f.write(\"epoch:[%d] train loss:[%.5f] vali loss:[%.5f] vali_accr:[%.5f]\\n\"%(epoch,loss_val_avg,vali_loss,vali_accr))\n",
    "      print(\"Model Save....\\n\")\n",
    "      torch.save({'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict()}, './checkpoint/'+str(current_fold)+'_VPT_epoch_'+str(epoch)+'.tar')\n",
    "    else:\n",
    "      print(\"epoch:[%d] train loss:[%.5f] vali loss:[%.5f] vali_accr:[%.5f]\\n\"%(epoch,loss_val_avg,vali_loss,vali_accr))\n",
    "      f.write(\"epoch:[%d] train loss:[%.5f] vali loss:[%.5f] vali_accr:[%.5f]\\n\"%(epoch,loss_val_avg,vali_loss,vali_accr))\n",
    "    scheduler.step(vali_loss) # LR Scheduler\n",
    "\n",
    "    if prev_vali_loss<vali_loss: #Stop Train\n",
    "      flag+=1\n",
    "      if flag==10 : \n",
    "        print(\"Stop Training...\\n\")\n",
    "        break\n",
    "    if best_vali_loss>vali_loss:\n",
    "      flag=0\n",
    "      best_vali_loss=vali_loss\n",
    "    prev_vali_loss=vali_loss\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85822bcc-e0a2-4e77-92fd-7dca1b26c96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f98132bd-209c-4d88-94bb-71f3682c7cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[ 2.2489,  2.2489,  2.2489,  ..., -0.4910, -0.0598,  0.2982],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.5508, -0.0687, -0.1299],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ..., -0.2422, -0.2603, -0.1485],\n",
      "          ...,\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ..., -0.4640,  0.0993,  0.5209],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.5219,  0.0903,  0.0832],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ..., -0.1579, -0.1039,  0.0618],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ..., -0.6255, -0.0623,  0.4076],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.6822, -0.0714, -0.0784],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ..., -0.3359, -0.2652, -0.0997],\n",
      "          ...,\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          ...,\n",
      "          [ 1.2389,  1.2557,  1.2557,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.2389,  1.2557,  1.2557,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.2389,  1.2557,  1.2557,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 1.2209,  1.2381,  1.2381,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.2209,  1.2381,  1.2381,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 1.2209,  1.2381,  1.2381,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          ...,\n",
      "          [ 1.3157,  1.3328,  1.3328,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.3157,  1.3328,  1.3328,  ...,  2.6400,  2.6400,  2.6400],\n",
      "          [ 1.3157,  1.3328,  1.3328,  ...,  2.6400,  2.6400,  2.6400]]]]), tensor([1, 5])]\n"
     ]
    }
   ],
   "source": [
    "dataloader_iter = iter(train_iter)\n",
    "batch = next(dataloader_iter)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0ab5066e-b5ab-46be-951b-bb832e229595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4289a-6878-47b9-b007-980978656a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
